<style>lay_fix{table-layout:fixed}wid20{width:20%}wid60{width:60%}</style>
<table class="lay_fix">
<thead>
<tr>
<th class="wid20">Task</th>
<th class="wid20">Dataset</th>
<th class="wid60">Downloaded Source</th>
</tr>
</thead>
<tbody><tr>
<td align="center" rowspan="3"><strong>Unconditional</strong></td>
<td align="center">Image COCO Caption</td>
<td style="word-break:break-all;"><a href="https://github.com/pclucas14/GansFallingShort/tree/master/real_data_experiments/data/coco">https://github.com/pclucas14/GansFallingShort/tree/master/real_data_experiments/data/coco</a></td>
</tr>
<tr>
<td align="center">EMNLP2017 WMT News</td>
<td style="word-break:break-all;"><a href="https://github.com/pclucas14/GansFallingShort/tree/master/real_data_experiments/data/news">https://github.com/pclucas14/GansFallingShort/tree/master/real_data_experiments/data/news</a></td>
</tr>
<tr>
<td align="center">IMDB Movie Review</td>
<td style="word-break:break-all;"><a href="https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz">https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz</a></td>
</tr>
<tr>
<td align="center" rowspan="2"><strong>Translation</strong></td>
<td align="center">IWSLT2014 German-English</td>
<td style="word-break:break-all;"><a href="https://github.com/facebookarchive/MIXER/blob/master/prepareData.sh">https://github.com/facebookarchive/MIXER/blob/master/prepareData.sh</a></td>
</tr>
<tr>
<td align="center">WMT2014 English-German</td>
<td style="word-break:break-all;"><a href="https://github.com/terranceliu/fairseq/blob/efficient_decoding/examples/translation/prepare-wmt14en2de.sh">https://github.com/terranceliu/fairseq/blob/efficient_decoding/examples/translation/prepare-wmt14en2de.sh</a></td>
</tr>
<tr>
<td align="center"><strong>Summarization</strong></td>
<td align="center">GigaWord</td>
<td style="word-break:break-all;"><a href="https://github.com/microsoft/unilm/tree/master/unilm-v1#abstractive-summarization---gigaword">https://github.com/microsoft/unilm/tree/master/unilm-v1#abstractive-summarization---gigaword</a></td>
</tr>
</tbody></table>